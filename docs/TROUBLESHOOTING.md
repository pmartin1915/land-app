# Alabama Auction Watcher - Troubleshooting Guide Comprehensive troubleshooting guide for resolving common issues with the Alabama Auction Watcher system. ## Quick Issue Resolution ### Most Common Issues (Quick Fixes) | Issue | Symptoms | Quick Fix | |-------|----------|-----------| | Invalid county error | `CountyValidationError: Invalid county 'XYZ'` | Run `python scripts/parser.py --list-counties` to see valid names | | No data found | `No data found for [County] County` | County has no delinquent properties (normal) | | Connection timeout | `NetworkError: HTTP request failed` | Check internet connection, try again later | | Port already in use | `Port 8501 is already in use` | Use different port: `--server.port 8502` | | Module not found | `ModuleNotFoundError: No module named 'X'` | Run `pip install -r requirements.txt` | ## Installation & Setup Issues ### Python Environment Problems #### Issue: Wrong Python Version ```bash # Symptoms python --version # Shows Python 2.x or < 3.10 # Solution # Install Python 3.10+ from python.org # Or use pyenv (Linux/macOS) pyenv install 3.11.9 pyenv local 3.11.9 ``` #### Issue: Virtual Environment Problems ```bash # Symptoms ModuleNotFoundError even after pip install # Solution # Recreate virtual environment rm -rf auction-env python -m venv auction-env source auction-env/bin/activate # Linux/macOS # or auction-env\Scripts\activate # Windows pip install -r requirements.txt ``` #### Issue: Dependencies Installation Fails ```bash # Symptoms ERROR: Failed building wheel for lxml # Solution - Install system dependencies first # Ubuntu/Debian: sudo apt-get install python3-dev libxml2-dev libxslt1-dev # CentOS/RHEL: sudo yum install python3-devel libxml2-devel libxslt-devel # macOS: brew install libxml2 libxslt # Windows: Use pre-compiled wheels pip install --only-binary=all lxml ``` ### Permission Issues #### Issue: File Permission Denied ```bash # Symptoms PermissionError: [Errno 13] Permission denied: 'data/raw/file.csv' # Solution # Fix directory permissions chmod -R 755 data/ # Or run with appropriate user sudo chown -R $USER:$USER data/ ``` ## ï¸ Web Scraping Issues ### Connection Problems #### Issue: Cannot Connect to ADOR Website ```bash # Symptoms NetworkError: HTTP request failed: Connection timeout # Diagnosis curl -I https://www.revenue.alabama.gov ping www.revenue.alabama.gov # Solutions 1. Check internet connection 2. Check DNS resolution: nslookup www.revenue.alabama.gov 3. Check firewall/proxy settings 4. Try different network 5. Wait and retry later (server might be down) ``` #### Issue: Rate Limiting / HTTP 429 ```bash # Symptoms NetworkError: HTTP request failed: 429 Too Many Requests # Solution # Increase delay between requests export SCRAPING_DELAY=5.0 python scripts/parser.py --scrape-county Baldwin --max-pages 1 ``` #### Issue: SSL Certificate Problems ```bash # Symptoms SSL: CERTIFICATE_VERIFY_FAILED # Solution # Update certificates pip install --upgrade certifi requests # Or temporarily bypass (NOT recommended for production) export PYTHONHTTPSVERIFY=0 ``` ### Data Extraction Issues #### Issue: No Tables Found ```bash # Symptoms WARNING: pandas.read_html failed: No tables found WARNING: No table found in HTML # This is normal! The system falls back to BeautifulSoup parsing # If scraping still fails: # Solution 1. Check if county has any delinquent properties 2. Verify county code/name is correct 3. Check if ADOR website structure changed 4. Review scraped HTML content for debugging ``` #### Issue: Inconsistent Data Formats ```bash # Symptoms DataProcessingError: Cannot convert to number # Solution # The system handles most format variations automatically # For persistent issues, check raw scraped data: ls -la data/raw/scraped_*_county_*.csv head data/raw/scraped_county_latest.csv ``` ## Data Processing Issues ### CSV File Problems #### Issue: CSV File Not Found ```bash # Symptoms FileNotFoundError: [Errno 2] No such file or directory: 'data/raw/file.csv' # Solution # Verify file exists and path is correct ls -la data/raw/ # Use absolute path if needed python scripts/parser.py --input /full/path/to/file.csv ``` #### Issue: CSV Encoding Problems ```bash # Symptoms UnicodeDecodeError: 'utf-8' codec can't decode byte # Solution - The system tries multiple encodings automatically # For persistent issues, manually specify encoding in utils.py # or convert file: iconv -f ISO-8859-1 -t UTF-8 problematic_file.csv > converted_file.csv ``` #### Issue: Malformed CSV Data ```bash # Symptoms ParserError: Error tokenizing data # Solution # Check file with text editor for malformed rows # The system includes error handling for most issues # For persistent problems, clean the CSV: python -c " import pandas as pd df = pd.read_csv('file.csv', on_bad_lines='skip', engine='python') df.to_csv('cleaned_file.csv', index=False) " ``` ### Filtering & Processing Issues #### Issue: No Properties Pass Filters ```bash # Symptoms Filter Retention Rate: 0.0% Successfully exported 0 properties # Solution # Adjust filter criteria in config/settings.py MIN_ACRES = 0.5 # Lower minimum MAX_ACRES = 10.0 # Higher maximum MAX_PRICE = 50000.0 # Higher price limit # Or use command line options python scripts/parser.py --input file.csv --min-acres 0.1 --max-price 100000 ``` #### Issue: Acreage Inference Not Working ```bash # Symptoms 0 properties with inferred acreage # Solution # Enable acreage inference explicitly python scripts/parser.py --input file.csv --infer-acres # Check legal descriptions in your data # The system looks for patterns like "2.5 AC", "100' X 200'", etc. ``` ## Dashboard Issues ### Streamlit Problems #### Issue: Dashboard Won't Start ```bash # Symptoms Error: Address already in use # Solution # Check what's using the port netstat -tlnp | grep 8501 # or lsof -i :8501 # Kill process or use different port python -m streamlit run streamlit_app/app.py --server.port 8502 ``` #### Issue: Dashboard Loads but Shows Errors ```bash # Symptoms FileNotFoundError in dashboard AttributeError: module 'streamlit' has no attribute 'cache_data' # Solution # Update streamlit to latest version pip install --upgrade streamlit # Clear streamlit cache streamlit cache clear # Check data files exist ls -la data/processed/ ``` #### Issue: Blank Dashboard / No Data ```bash # Symptoms Dashboard loads but shows "No data available" # Solution # Generate some data first python scripts/parser.py --scrape-county Baldwin --infer-acres # Check data directory ls -la data/processed/*.csv # Verify CSV files have content wc -l data/processed/*.csv ``` ### Performance Issues #### Issue: Dashboard Slow/Unresponsive ```bash # Symptoms High CPU usage, slow loading times # Solution # Reduce data size head -n 1000 large_dataset.csv > smaller_dataset.csv # Enable data caching in streamlit_app/app.py @st.cache_data(ttl=3600) # Increase system resources # Check memory usage free -h top -p $(pgrep -f streamlit) ``` ## Debugging & Diagnostics ### Enable Debug Logging ```bash # Set environment variable export LOG_LEVEL=DEBUG export LOG_DETAILED=true # Run with verbose logging python scripts/parser.py --scrape-county Baldwin --max-pages 1 # Check log file tail -f logs/auction_watcher.log ``` ### Manual Testing Steps #### Test Web Scraping ```bash # 1. Test county validation python -c " from scripts.scraper import validate_county_code print(validate_county_code('Baldwin')) print(validate_county_code('05')) " # 2. Test simple scraping python scripts/parser.py --scrape-county Baldwin --max-pages 1 # 3. Test with known good county python scripts/parser.py --scrape-county Barbour --max-pages 2 ``` #### Test Data Processing ```bash # 1. Test CSV processing python scripts/parser.py --input data/raw/scraped_baldwin_county_*.csv # 2. Test filtering python scripts/parser.py --input test.csv --min-acres 0.1 --max-acres 100 # 3. Test dashboard with data python -m streamlit run streamlit_app/app.py ``` ### System Diagnostics ```bash # Check system resources df -h # Disk space free -h # Memory top # CPU usage # Check network connectivity ping www.revenue.alabama.gov curl -I https://www.revenue.alabama.gov # Check Python environment python --version pip list | grep -E "(pandas|streamlit|requests|beautifulsoup4)" # Check file permissions ls -la data/ ls -la logs/ ``` ## Platform-Specific Issues ### Windows Issues #### Issue: Path Separator Problems ```bash # Symptoms FileNotFoundError with forward slashes in paths # Solution - Use os.path.join or pathlib python -c " from pathlib import Path print(Path('data') / 'raw' / 'file.csv') " ``` #### Issue: PowerShell Execution Policy ```powershell # Symptoms cannot be loaded because running scripts is disabled # Solution Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser ``` ### macOS Issues #### Issue: SSL Certificate Issues ```bash # Symptoms urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED]> # Solution /Applications/Python\ 3.x/Install\ Certificates.command # Or update certificates pip install --upgrade certifi ``` ### Linux Issues #### Issue: Missing System Libraries ```bash # Symptoms ImportError: No module named '_tkinter' # Solution # Ubuntu/Debian: sudo apt-get install python3-tk # CentOS/RHEL: sudo yum install tkinter ``` ## Emergency Procedures ### Complete System Reset ```bash # 1. Backup any important data cp -r data/processed data/processed_backup # 2. Reset Python environment rm -rf auction-env python -m venv auction-env source auction-env/bin/activate pip install -r requirements.txt # 3. Clear all caches rm -rf __pycache__/ rm -rf */__pycache__/ find . -name "*.pyc" -delete # 4. Test basic functionality python scripts/parser.py --list-counties ``` ### Data Recovery ```bash # Recover from raw scraped data ls data/raw/scraped_*_county_*.csv # Reprocess specific county python scripts/parser.py --input data/raw/scraped_county_date.csv --infer-acres # Restore from backup cp data/processed_backup/* data/processed/ ``` ## Diagnostic Checklist When reporting issues, include this information: ### System Information ```bash # Run this diagnostic script cat > diagnostic_info.sh << 'EOF' #!/bin/bash echo "=== System Information ===" uname -a python --version pip --version echo -e "\n=== Python Packages ===" pip list | grep -E "(pandas|streamlit|requests|beautifulsoup4|plotly)" echo -e "\n=== Directory Structure ===" ls -la echo -e "\n=== Data Directory ===" ls -la data/raw/ | head -10 ls -la data/processed/ | head -10 echo -e "\n=== Recent Logs ===" tail -20 logs/auction_watcher.log 2>/dev/null || echo "No log file found" echo -e "\n=== Network Test ===" curl -I https://www.revenue.alabama.gov 2>&1 | head -5 echo -e "\n=== Process Information ===" ps aux | grep -E "(python|streamlit)" | grep -v grep EOF chmod +x diagnostic_info.sh ./diagnostic_info.sh > diagnostic_report.txt ``` ### Error Context - Exact error message and stack trace - Command that caused the error - Expected vs actual behavior - System environment (OS, Python version) - Recent changes made to the system ## Getting Help ### Self-Help Resources 1. **Check logs**: `tail -f logs/auction_watcher.log` 2. **Review configuration**: Verify settings in `config/settings.py` 3. **Test components**: Use individual test commands above 4. **Check documentation**: README.md, DEPLOYMENT.md ### Escalation Path 1. **Level 1**: Use this troubleshooting guide 2. **Level 2**: Check GitHub issues and discussions 3. **Level 3**: Create detailed issue report with diagnostic information ### Bug Report Template ```markdown ## Issue Description Brief description of the problem ## Steps to Reproduce 1. Run command: `python scripts/parser.py --scrape-county X` 2. Observe error: [exact error message] ## Expected Behavior What should have happened ## Environment - OS: [Windows/macOS/Linux] - Python version: [output of python --version] - Dependencies: [output of pip list] ## Error Logs ``` [paste relevant log entries] ``` ## Additional Context Any other relevant information ``` --- **Remember**: Most issues are related to environment setup, network connectivity, or data availability. The troubleshooting steps above resolve 95% of common problems. **Last Updated**: September 2025 **Version**: 1.0